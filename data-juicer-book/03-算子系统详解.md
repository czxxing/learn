# 第3章：算子系统详解

[← 上一章](02-数据处理核心机制.md) | [返回目录](00-目录与索引.md) | [下一章 →](04-数据集管理.md)

---

## 3.1 算子分类与设计

Data-Juicer采用了模块化、可扩展的算子设计，通过抽象基类和注册机制实现了丰富的数据处理功能。算子被划分为七大类别，每种类型负责不同的数据处理任务。

### 算子分类体系

```python
# 七大算子类别
OPERATOR_CATEGORIES = {
    "mapper": "修改/转换数据内容",
    "filter": "根据条件过滤数据", 
    "deduplicator": "去除重复数据",
    "selector": "在数据集级别进行选择操作",
    "grouper": "对样本进行分组批处理",
    "aggregator": "聚合分组后的样本",
    "formatter": "格式化数据"
}
```

### 注册机制

系统使用Registry模式管理所有算子，通过`OPERATORS`注册器统一注册和获取：

```python
@OPERATORS.register_module("text_length_filter")
class TextLengthFilter(Filter):
    """文本长度过滤器"""
    def __init__(self, min_len=10, max_len=1000, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.min_len = min_len
        self.max_len = max_len
```

## 3.2 核心基类实现

### OP基类

`OP`基类是所有算子的基础，提供了共享功能：

```python
class OP(ABC):
    """所有算子的抽象基类"""
    
    def __init__(self, text_key="text", image_key="images", 
                 audio_key="audios", video_key="videos", **kwargs):
        # 多模态数据支持
        self.text_key = text_key
        self.image_key = image_key  
        self.audio_key = audio_key
        self.video_key = video_key
        
        # 资源管理
        self.cpu_required = kwargs.get("cpu_required", 1)
        self.gpu_required = kwargs.get("gpu_required", 0)
        self.batch_size = kwargs.get("batch_size", 32)
        self.num_proc = kwargs.get("num_proc", 1)
        
        # 异常处理装饰器
        self.process = catch_exception(self.process)
    
    @abstractmethod
    def process(self, sample):
        """处理单个样本"""
        pass
```

### Mapper实现

Mapper负责数据转换，核心特点：

```python
class Mapper(OP):
    """数据转换算子基类"""
    
    def process_single(self, sample):
        """单样本处理接口"""
        return self._process_single(sample)
    
    def process_batched(self, samples):
        """批量处理接口"""
        return self._process_batched(samples)
    
    @abstractmethod
    def _process_single(self, sample):
        """单样本处理实现"""
        pass
    
    @abstractmethod  
    def _process_batched(self, samples):
        """批量处理实现"""
        pass
```

#### 示例：WhitespaceNormalizationMapper

```python
@OPERATORS.register_module("whitespace_normalization_mapper")
class WhitespaceNormalizationMapper(Mapper):
    """空白字符标准化映射器"""
    
    def process_batched(self, samples):
        for idx, text in enumerate(samples[self.text_key]):
            # 去除首尾空白
            text = text.strip()
            # 标准化各种空白字符
            samples[self.text_key][idx] = "".join([
                char if char not in VARIOUS_WHITESPACES else " " 
                for char in text
            ])
        return samples
```

### Filter实现

Filter负责数据过滤，采用两阶段处理模式：

```python
class Filter(OP):
    """数据过滤算子基类"""
    
    def compute_stats(self, sample):
        """计算统计特征"""
        return self._compute_stats(sample)
    
    def process(self, sample):
        """基于统计特征进行过滤决策"""
        stats = sample.get(Fields.stats, {})
        return self._process(sample, stats)
    
    @abstractmethod
    def _compute_stats(self, sample):
        """统计特征计算实现"""
        pass
    
    @abstractmethod
    def _process(self, sample, stats):
        """过滤决策实现"""
        pass
```

#### 示例：TextLengthFilter

```python
@OPERATORS.register_module("text_length_filter")
class TextLengthFilter(Filter):
    """文本长度过滤器"""
    
    def compute_stats_batched(self, samples):
        # 计算文本长度并存储到统计信息中
        samples_list = samples[self.text_key]
        samples_stats = samples[Fields.stats]
        for i, stat in enumerate(samples_stats):
            if StatsKeys.text_len not in stat:
                samples_stats[i][StatsKeys.text_len] = len(samples_list[i])
        return samples
    
    def process_batched(self, samples):
        # 根据预定义的长度范围决定是否保留样本
        return map(
            lambda stat: self.get_keep_boolean(
                stat[StatsKeys.text_len], self.min_len, self.max_len
            ),
            samples[Fields.stats],
        )
```

### Deduplicator实现

Deduplicator负责数据去重，支持多种去重策略：

```python
class Deduplicator(OP):
    """数据去重算子基类"""
    
    def __init__(self, method="exact", **kwargs):
        super().__init__(**kwargs)
        self.method = method
        self.seen = set()  # 已见样本集合
    
    def process(self, sample):
        """去重处理"""
        signature = self._generate_signature(sample)
        if signature in self.seen:
            return None  # 重复样本，返回None表示过滤
        else:
            self.seen.add(signature)
            return sample
    
    @abstractmethod
    def _generate_signature(self, sample):
        """生成样本签名"""
        pass
```

#### 示例：DocumentDeduplicator

```python
@OPERATORS.register_module("document_deduplicator")
class DocumentDeduplicator(Deduplicator):
    """文档去重器"""
    
    def _generate_signature(self, sample):
        # 基于文本内容生成MD5签名
        text = sample.get(self.text_key, "")
        return hashlib.md5(text.encode()).hexdigest()
```

## 3.3 常用算子实现

### 文本处理算子

#### 1. 文本清洗算子

```python
@OPERATORS.register_module("text_clean_mapper")
class TextCleanMapper(Mapper):
    """文本清洗映射器"""
    
    def _process_single(self, sample):
        text = sample.get(self.text_key, "")
        # 移除HTML标签
        text = re.sub(r'<[^>]+>', '', text)
        # 标准化URL
        text = re.sub(r'http\S+', '[URL]', text)
        # 移除多余空白
        text = re.sub(r'\s+', ' ', text).strip()
        sample[self.text_key] = text
        return sample
```

#### 2. 语言检测过滤器

```python
@OPERATORS.register_module("language_filter")
class LanguageFilter(Filter):
    """语言过滤器"""
    
    def __init__(self, target_language="en", **kwargs):
        super().__init__(**kwargs)
        self.target_language = target_language
        self.detector = prepare_model("fasttext")
    
    def _compute_stats(self, sample):
        text = sample.get(self.text_key, "")
        lang = self.detector.detect_language(text)
        sample[Fields.stats][StatsKeys.language] = lang
        return sample
    
    def _process(self, sample, stats):
        lang = stats.get(StatsKeys.language, "")
        return lang == self.target_language
```

### 图像处理算子

#### 1. 图像质量过滤器

```python
@OPERATORS.register_module("image_quality_filter")
class ImageQualityFilter(Filter):
    """图像质量过滤器"""
    
    def __init__(self, min_quality=0.7, **kwargs):
        super().__init__(**kwargs)
        self.min_quality = min_quality
        self.quality_model = prepare_model("simple_aesthetics")
    
    def _compute_stats(self, sample):
        image_paths = sample.get(self.image_key, [])
        qualities = []
        for img_path in image_paths:
            quality = self.quality_model.evaluate(img_path)
            qualities.append(quality)
        sample[Fields.stats][StatsKeys.image_quality] = qualities
        return sample
    
    def _process(self, sample, stats):
        qualities = stats.get(StatsKeys.image_quality, [])
        if not qualities:
            return False
        return min(qualities) >= self.min_quality
```

#### 2. 图像尺寸调整映射器

```python
@OPERATORS.register_module("image_resize_mapper")
class ImageResizeMapper(Mapper):
    """图像尺寸调整映射器"""
    
    def __init__(self, target_size=(224, 224), **kwargs):
        super().__init__(**kwargs)
        self.target_size = target_size
    
    def _process_single(self, sample):
        image_paths = sample.get(self.image_key, [])
        resized_paths = []
        for img_path in image_paths:
            # 调整图像尺寸
            img = Image.open(img_path)
            img_resized = img.resize(self.target_size)
            # 保存调整后的图像
            resized_path = self._save_resized_image(img_resized, img_path)
            resized_paths.append(resized_path)
        sample[self.image_key] = resized_paths
        return sample
```

### 多模态算子

#### 1. 图文匹配过滤器

```python
@OPERATORS.register_module("image_text_match_filter")
class ImageTextMatchFilter(Filter):
    """图文匹配过滤器"""
    
    def __init__(self, min_similarity=0.5, **kwargs):
        super().__init__(**kwargs)
        self.min_similarity = min_similarity
        self.clip_model = prepare_model("clip")
    
    def _compute_stats(self, sample):
        text = sample.get(self.text_key, "")
        image_paths = sample.get(self.image_key, [])
        
        similarities = []
        for img_path in image_paths:
            similarity = self.clip_model.compute_similarity(text, img_path)
            similarities.append(similarity)
        
        sample[Fields.stats][StatsKeys.image_text_similarity] = similarities
        return sample
    
    def _process(self, sample, stats):
        similarities = stats.get(StatsKeys.image_text_similarity, [])
        if not similarities:
            return False
        return max(similarities) >= self.min_similarity
```

## 3.4 自定义算子开发

### 开发步骤

#### 1. 定义算子类

```python
@OPERATORS.register_module("custom_text_filter")
class CustomTextFilter(Filter):
    """自定义文本过滤器"""
    
    def __init__(self, keyword="important", **kwargs):
        super().__init__(**kwargs)
        self.keyword = keyword
    
    def _compute_stats(self, sample):
        text = sample.get(self.text_key, "")
        # 计算关键词出现频率
        keyword_count = text.lower().count(self.keyword.lower())
        sample[Fields.stats]["keyword_frequency"] = keyword_count
        return sample
    
    def _process(self, sample, stats):
        frequency = stats.get("keyword_frequency", 0)
        return frequency > 0  # 包含关键词则保留
```

#### 2. 配置算子参数

```yaml
process:
  - name: custom_text_filter
    args:
      keyword: "data-juicer"
      text_key: "text"
```

#### 3. 测试算子功能

```python
# 测试自定义算子
def test_custom_operator():
    # 创建测试样本
    sample = {"text": "This is a data-juicer example"}
    
    # 初始化算子
    op = CustomTextFilter(keyword="data-juicer")
    
    # 计算统计信息
    sample_with_stats = op.compute_stats(sample)
    
    # 执行过滤
    should_keep = op.process(sample_with_stats)
    print(f"Sample should be kept: {should_keep}")  # 应该输出True
```

### 最佳实践

1. **遵循命名规范**：使用有意义的算子名称
2. **提供完整文档**：包含算子功能、参数说明和使用示例
3. **实现批量处理**：尽可能支持批量处理以提高性能
4. **处理异常情况**：包含完善的异常处理机制
5. **支持多模态**：考虑文本、图像、音频等多种数据类型

## 3.5 算子性能优化

### 批量处理优化

```python
def process_batched(self, samples):
    """批量处理优化示例"""
    texts = samples[self.text_key]
    
    # 使用向量化操作替代循环
    processed_texts = []
    for text in texts:
        # 批量处理逻辑
        processed_text = self._process_single_text(text)
        processed_texts.append(processed_text)
    
    samples[self.text_key] = processed_texts
    return samples
```

### 内存优化

```python
def process(self, sample):
    """内存优化示例"""
    # 及时释放大对象
    large_object = self._load_large_resource()
    result = self._process_with_resource(sample, large_object)
    del large_object  # 及时释放内存
    return result
```

### GPU加速

```python
def __init__(self, **kwargs):
    super().__init__(**kwargs)
    # 配置GPU资源
    self.gpu_required = 1
    self.batch_size = 64  # 增大批处理大小以充分利用GPU
```

通过这种模块化的算子设计，Data-Juicer能够灵活应对各种复杂的数据处理需求，同时保持代码的可维护性和扩展性。